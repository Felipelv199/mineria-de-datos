{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"../../data/hotel_bookings.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limpiar base de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_dtypes = dict(data.dtypes)\n",
    "columns2drop = []\n",
    "\n",
    "for dtype in dict_dtypes:\n",
    "    column_type = dict_dtypes[dtype]\n",
    "    if column_type == \"object\":\n",
    "        columns2drop.append(dtype)\n",
    "\n",
    "clean_data = data.drop(columns2drop, 1)\n",
    "\n",
    "columns2drop = []\n",
    "for column in clean_data.columns:\n",
    "    column_data = clean_data[column]\n",
    "    isna_cd = column_data.isna()\n",
    "    if isna_cd.describe()[\"top\"]:\n",
    "        columns2drop.append(column)\n",
    "    else:\n",
    "        clean_data[column] = clean_data[column].fillna(0)\n",
    "\n",
    "clean_data = clean_data.drop(columns2drop, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separar columna binarias de las otras\n",
    "* **X:** Columna binarias\n",
    "* **Y:** Otras columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_df = clean_data.values\n",
    "y = array_df[:, 0]\n",
    "x = array_df[:, 1:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k-fold Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 73.56% 0.36%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score  # Metodo de validación\n",
    "from sklearn.model_selection import KFold  # Iteraciones\n",
    "from sklearn.linear_model import LogisticRegression  # Modelo matemático\n",
    "\n",
    "num_folds = 10\n",
    "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
    "model = LogisticRegression(solver=\"lbfgs\", max_iter=4000)\n",
    "results = cross_val_score(model, x, y, cv=kfold)\n",
    "mean_p = results.mean()*100.0\n",
    "std_p = results.std()*100.0\n",
    "print(f\"Accuracy: {mean_p:,.2f}% {std_p:,.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Repeated train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 73.56% 0.00%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split  # División por porcentaje\n",
    "from sklearn.linear_model import LogisticRegression  # Modelo matemático\n",
    "import math\n",
    "\n",
    "test_size = .33\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=test_size)\n",
    "model = LogisticRegression(solver=\"lbfgs\", max_iter=4000)\n",
    "model.fit(x_train, y_train)\n",
    "results = model.score(x_test, y_test)\n",
    "mean_p = results.mean()*100.0\n",
    "std_p = results.std()*100.0\n",
    "print(f\"Accuracy: {mean_p:,.2f}% {std_p:,.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standarize values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(x)\n",
    "x_scaled = scaler.transform(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k-fold Cross-validation of standarize values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 73.69% 0.45%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold  # Iteraciones\n",
    "from sklearn.model_selection import cross_val_score  # Metodo de validación\n",
    "from sklearn.linear_model import LogisticRegression  # Modelo matemático\n",
    "\n",
    "num_folds = 10\n",
    "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
    "model = LogisticRegression(solver=\"lbfgs\", max_iter=1000)\n",
    "results = cross_val_score(model, x_scaled, y, cv=kfold)\n",
    "mean_p = results.mean()*100.0\n",
    "std_p = results.std()*100.0\n",
    "print(f\"Accuracy: {mean_p:,.2f}% {std_p:,.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Repeated train and test of standarize values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 73.55% 0.00%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split  # División por porcentaje\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "test_size = .33\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_scaled, y, test_size=test_size)\n",
    "model = LogisticRegression(solver=\"lbfgs\", max_iter=1000)\n",
    "model.fit(x_train, y_train)\n",
    "results = model.score(x_test, y_test)\n",
    "mean_p = results.mean()*100.0\n",
    "std_p = results.std()*100.0\n",
    "print(f\"Accuracy: {mean_p:,.2f}% {std_p:,.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_canceled\n",
       "0    75166\n",
       "1    44224\n",
       "dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby(\"is_canceled\").size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matriz de confusión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[21907  2976]\n",
      " [ 7342  7174]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "test_size = .33\n",
    "seed = 1\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=test_size, random_state=seed)\n",
    "model = LogisticRegression(max_iter=1900)\n",
    "model.fit(x_train, y_train)\n",
    "predicted = model.predict(x_test)\n",
    "matrix = confusion_matrix(y_test, predicted)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cohen kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.40\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "test_size = .33\n",
    "seed = 1\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=test_size, random_state=seed)\n",
    "model = LogisticRegression(max_iter=1900)\n",
    "model.fit(x_train, y_train)\n",
    "predicted = model.predict(x_test)\n",
    "cohen_score = cohen_kappa_score(y_test, predicted)\n",
    "print(f\"{cohen_score:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2db524e06e9f5f4ffedc911c917cb75e12dbc923643829bf417064a77eb14d37"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
